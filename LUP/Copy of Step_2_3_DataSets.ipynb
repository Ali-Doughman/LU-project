{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Copy of Step_2_3_DataSets.ipynb","provenance":[{"file_id":"1s0ctkgJjwe5HswqUU4UDU3hOmIY5ir5g","timestamp":1585689510141},{"file_id":"16Kezc5ukuGd5-S7MsG66ym9pRZN_6YzD","timestamp":1585514681086},{"file_id":"https://github.com/maoude/TFIntroduction/blob/master/exemple01.ipynb","timestamp":1583950759427}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"n6OzHNTtkkDh","colab_type":"code","outputId":"bb93b82e-7c4c-46fa-b6be-bef7227b513c","executionInfo":{"status":"ok","timestamp":1585689281820,"user_tz":-180,"elapsed":8835,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":632}},"source":["!pip install --upgrade tensorflow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n","Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n","Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post2)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.0.0)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0LGu1Y30iX3K","colab_type":"code","outputId":"31a59a38-2c03-4b60-e78a-38ea465bb288","executionInfo":{"status":"ok","timestamp":1585689288559,"user_tz":-180,"elapsed":2701,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["2.2.0-rc2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XfMgLG8XzyFi","colab_type":"code","outputId":"7bad5a7b-1ba6-40b4-8fcc-31e0be73c739","executionInfo":{"status":"ok","timestamp":1585689288556,"user_tz":-180,"elapsed":3605,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import tensorflow as tf\n","import numpy as np\n","import itertools \n","import collections\n","dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) # the simplest way to create a dataset is to create it from a python list:\n","for element in dataset: \n","  print(element)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tf.Tensor(1, shape=(), dtype=int32)\n","tf.Tensor(2, shape=(), dtype=int32)\n","tf.Tensor(3, shape=(), dtype=int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VMKDkbwtzyFw","colab_type":"code","outputId":"2e44a918-cb85-46b7-b8fd-ad4c548f4b05","executionInfo":{"status":"ok","timestamp":1585689295776,"user_tz":-180,"elapsed":2352,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])  # To process lines from files, use tf.data.TextLineDataset0\n","dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","dataset = dataset.map(lambda x: x*2) #  Once you have a dataset, you can apply transformations to prepare the data for your model:\n","list(dataset.as_numpy_iterator()) "],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 4, 6]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"HsG6sLe8zyF7","colab_type":"code","outputId":"7121f9a9-fedf-4df7-8995-a7c0ac025e83","executionInfo":{"status":"ok","timestamp":1585689295779,"user_tz":-180,"elapsed":1230,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Creates a dataset of a step-separated range of values\n","list(dataset.range(5).as_numpy_iterator()) \n","\n"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2, 3, 4]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"GUhg1S38zyGJ","colab_type":"code","outputId":"b33f2505-8ac0-4b22-c413-8f875ef4e247","executionInfo":{"status":"ok","timestamp":1585689296881,"user_tz":-180,"elapsed":1199,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(dataset.range(2, 5).as_numpy_iterator()) "],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 3, 4]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"d6rOGVWbzyGT","colab_type":"code","outputId":"2781c81a-3c3c-4faf-da34-b23b723699ae","executionInfo":{"status":"ok","timestamp":1585689298122,"user_tz":-180,"elapsed":1310,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(dataset.range(1, 5, 2).as_numpy_iterator()) "],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 3]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"FGFteqpazyGf","colab_type":"code","outputId":"03109635-7bd8-4b8c-9f97-ef65737f9258","executionInfo":{"status":"ok","timestamp":1585689306683,"user_tz":-180,"elapsed":3522,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(dataset.range(1, 5, -2).as_numpy_iterator()) "],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"GbYu1EO-zyGt","colab_type":"code","outputId":"2e7588f1-885e-48ad-cf44-5e5a0d6a4d81","executionInfo":{"status":"ok","timestamp":1585689306685,"user_tz":-180,"elapsed":2564,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(dataset.range(5, 1, -2).as_numpy_iterator()) "],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[5, 3]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"lR1_DHNnzyG5","colab_type":"code","outputId":"a96bfa76-eeef-4a99-9c62-abae31eaafd2","executionInfo":{"status":"ok","timestamp":1585689310021,"user_tz":-180,"elapsed":2477,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(dataset.range(5, 1).as_numpy_iterator()) "],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"SbnpLAgHzyHD","colab_type":"code","outputId":"251e9b03-0247-43f5-bcaf-e16dbac91aa4","executionInfo":{"status":"ok","timestamp":1585689311527,"user_tz":-180,"elapsed":2115,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Reduces the input dataset to a single element.\n","tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy() \n","#reduce(initial_state, reduce_func)\n","#Reduces the input dataset to a single element.\n","#The transformation calls reduce_func successively on every element \n","#of the input dataset until the dataset is exhausted, \n","#aggregating information in its internal state. \n","#The initial_state argument is used for the initial state \n","# and the final state is returned as the result."],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"0T3YUFfmzyHJ","colab_type":"code","outputId":"585e8494-52ef-4a26-d50f-63c36a4c66f2","executionInfo":{"status":"ok","timestamp":1585689317267,"user_tz":-180,"elapsed":1490,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"VFKN4_8ozyHR","colab_type":"code","outputId":"b09b22a5-9c38-4aab-edfe-4cb5ff73af31","executionInfo":{"status":"ok","timestamp":1585689318408,"user_tz":-180,"elapsed":1721,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","dataset = dataset.repeat(3) \n","list(dataset.as_numpy_iterator()) \n","#Repeats this dataset so each original value is seen count times."],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3, 1, 2, 3, 1, 2, 3]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"fV5_YKF1zyHV","colab_type":"code","outputId":"292a4113-6ae5-4f25-a950-097b1152c3b3","executionInfo":{"status":"ok","timestamp":1585689319922,"user_tz":-180,"elapsed":2307,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n","dataset = dataset.map(lambda x: x + 1) \n","#  Maps map_func across the elements of this dataset.\n","list(dataset.as_numpy_iterator())"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 3, 4, 5, 6]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"xbIzPUlFzyHb","colab_type":"code","colab":{}},"source":["dataset = dataset.range(5) \n","# `map_func` takes a single argument of type `tf.Tensor` with the same \n","# shape and dtype. \n","result = dataset.map(lambda x: x + 1) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VftZ3OsCzyHi","colab_type":"code","outputId":"e05a65a6-d2ea-481a-af2a-f82c9104e351","executionInfo":{"status":"ok","timestamp":1585689324831,"user_tz":-180,"elapsed":1006,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Each element is a tuple containing two `tf.Tensor` objects. \n","elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz)\")] \n","dataset = tf.data.Dataset.from_generator( \n","    lambda: elements, (tf.int32, tf.string)) \n","# `map_func` takes two arguments of type `tf.Tensor`. This function \n","# projects out just the first component. \n","result = dataset.map(lambda x_int, y_str: x_int) \n","list(result.as_numpy_iterator()) "],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"8t5vIHVXzyHn","colab_type":"code","outputId":"6ee86748-c5af-46fc-916a-a1625488896e","executionInfo":{"status":"ok","timestamp":1585689327058,"user_tz":-180,"elapsed":2003,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","import numpy as np\n","import itertools \n","import collections\n","a = 1 # Integer element \n","b = 2.0 # Float element \n","c = (1, 2) # Tuple element with 2 components \n","d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components \n","Point = collections.namedtuple(\"Point\", [\"x\", \"y\"]) # doctest: +SKIP Elements can be nested structures of tuples, named tuples, and dictionaries.\n","e = Point(1, 2) # Named tuple # doctest: +SKIP \n","f = tf.data.Dataset.range(10) # Dataset element \n","e                  # readable __repr__ with a name=value style"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Point(x=1, y=2)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"KbhhElNRzyHu","colab_type":"code","outputId":"21f6ccdf-0c05-4dd0-d692-efef23d9ed6b","executionInfo":{"status":"ok","timestamp":1585689330979,"user_tz":-180,"elapsed":1614,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["e[0] + e[1] # indexable like the plain tuple (1, 2)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"GrNyJS1bzyH5","colab_type":"code","colab":{}},"source":["x, y = e                # unpack like a regular tuple"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WFvKTEPjzyH-","colab_type":"code","outputId":"f1b339b3-ae6a-447e-879c-78f766292340","executionInfo":{"status":"ok","timestamp":1585689332427,"user_tz":-180,"elapsed":1549,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x, y"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 2)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"nezjMwkPzyIC","colab_type":"code","outputId":"add840c8-8897-4269-d529-4ade06906014","executionInfo":{"status":"ok","timestamp":1585689333414,"user_tz":-180,"elapsed":1719,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["e.x + e.y               # fields also accessible by name"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"wIR0pqMqzyII","colab_type":"code","colab":{}},"source":["dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]).element_spec  # element_spec: The type specification of an element of this dataset."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Isc_TOOezyIM","colab_type":"code","outputId":"3f5ce325-dfcc-4de6-b07f-690353cbdb18","executionInfo":{"status":"ok","timestamp":1584025884994,"user_tz":-120,"elapsed":6368,"user":{"displayName":"alouchti Aoude","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt9NSrACoHN8LBM1RVz5QGgot5Gd3DPDBNRC2B=s64","userId":"14305235845289320415"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.range(100) \n","def dataset_fn(ds): # transformation_func: A function that takes one Dataset argument and returns a Dataset.\n","  return ds.filter(lambda x: x < 5) \n","dataset = dataset.apply(dataset_fn) # apply enables chaining of custom Dataset transformations, which are represented as functions that take one Dataset argument and return a transformed Dataset.\n","list(dataset.as_numpy_iterator()) # Returns an iterator which converts all elements of the dataset to numpy."],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2, 3, 4]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"aoJRgCFSzyIU","colab_type":"code","outputId":"2fae482f-f32d-4845-b9c9-f9122fcdfe8c","executionInfo":{"status":"ok","timestamp":1585689341073,"user_tz":-180,"elapsed":2536,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","for element in dataset.as_numpy_iterator(): \n","  print(element)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bztE1DAOzyIZ","colab_type":"code","outputId":"c80101ff-5465-48a0-afa2-2ef9f2b4325d","executionInfo":{"status":"ok","timestamp":1585689341075,"user_tz":-180,"elapsed":1288,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","print(list(dataset.as_numpy_iterator())) "],"execution_count":24,"outputs":[{"output_type":"stream","text":["[1, 2, 3]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e6ZUx9DDzyIe","colab_type":"code","outputId":"0d7bd1d7-62a3-42a5-ce7a-1ac8599342ec","executionInfo":{"status":"ok","timestamp":1585689346238,"user_tz":-180,"elapsed":1615,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), \n","                                              'b': [5, 6]}) \n","list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5}, # as_numpy_iterator() will preserve the nested structure of dataset elements.\n","                                      {'a': (2, 4), 'b': 6}] "],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"kaiusP8jzyIl","colab_type":"code","outputId":"4c8e9e87-1076-4f45-aab4-011dfdef93f9","executionInfo":{"status":"ok","timestamp":1585689346706,"user_tz":-180,"elapsed":890,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.range(8)  \n","dataset = dataset.batch(3) # Combines consecutive elements of this dataset into batches.\n","list(dataset.as_numpy_iterator()) "],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"jtqBv9gXzyIr","colab_type":"code","outputId":"160269f3-d586-4e4c-83ee-cac1221dcf99","executionInfo":{"status":"ok","timestamp":1585689351368,"user_tz":-180,"elapsed":1798,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.range(8) \n","dataset = dataset.batch(3, drop_remainder=True) #  If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to True to prevent the smaller batch from being produced.\n","list(dataset.as_numpy_iterator()) "],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([0, 1, 2]), array([3, 4, 5])]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"ioklpGSKzyIx","colab_type":"code","outputId":"61d94caa-9ef5-489b-a8b5-1ebb7a921ccb","executionInfo":{"status":"ok","timestamp":1585689354964,"user_tz":-180,"elapsed":1847,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.range(5) \n","dataset = dataset.map(lambda x: x**2) \n","dataset = dataset.cache() #Caches the elements in this dataset.\n","# The first time reading through the data will generate the data using \n","# `range` and `map`. \n","list(dataset.as_numpy_iterator()) "],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 4, 9, 16]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"7XtuMhhszyI4","colab_type":"code","outputId":"1a5d4cf6-36ac-436a-eb12-e53fcf8435d1","executionInfo":{"status":"ok","timestamp":1585689356174,"user_tz":-180,"elapsed":1821,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Subsequent iterations read from the cache. \n","list(dataset.as_numpy_iterator()) "],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 4, 9, 16]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"_GOPLCdnzyI8","colab_type":"code","outputId":"27cf6671-2441-425e-ad5e-310853edb8f3","executionInfo":{"status":"ok","timestamp":1585689356976,"user_tz":-180,"elapsed":1609,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ] \n","b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ] \n","ds = a.concatenate(b) # Creates a Dataset by concatenating the given dataset with this dataset.\n","list(ds.as_numpy_iterator())"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3, 4, 5, 6, 7]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"UmTwIWfHzyJA","colab_type":"code","outputId":"041a5d54-9cc4-4db6-9a44-3b0031f452e2","executionInfo":{"status":"ok","timestamp":1585689360518,"user_tz":-180,"elapsed":1944,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Slicing a 1D tensor produces scalar tensor elements. \n","dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","list(dataset.as_numpy_iterator()) "],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"hVT4COLwzyJJ","colab_type":"code","outputId":"61aad7b1-62b2-4db6-8f5f-f6c89612a3de","executionInfo":{"status":"ok","timestamp":1585689360520,"user_tz":-180,"elapsed":945,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Slicing a 1D tensor produces scalar tensor elements. \n","dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","list(dataset.as_numpy_iterator()) "],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"2QZGsfQJzyJP","colab_type":"code","outputId":"a2a335a0-ffa6-4a90-b91b-d71b9da687bd","executionInfo":{"status":"ok","timestamp":1585689365889,"user_tz":-180,"elapsed":2646,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Slicing a tuple of 1D tensors produces tuple elements containing \n","# scalar tensors. \n","dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6])) \n","list(dataset.as_numpy_iterator()) "],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(1, 3, 5), (2, 4, 6)]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"PzTLa731zyJT","colab_type":"code","outputId":"ff12fce9-4bac-4396-d34b-b3e871d72168","executionInfo":{"status":"ok","timestamp":1585689366306,"user_tz":-180,"elapsed":1819,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Dictionary structure is also preserved. \n","dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]}) \n","list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3}, \n","                                      {'a': 2, 'b': 4}]"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"vtKU5zUJzyJg","colab_type":"code","outputId":"1827f55a-3227-4756-8a05-aa4ae8ee0cd3","executionInfo":{"status":"ok","timestamp":1585689369291,"user_tz":-180,"elapsed":1246,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# Two tensors can be combined into one Dataset object. \n","features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor \n","labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor \n","dataset = dataset.from_tensor_slices((features, labels)) \n","# Both the features and the labels tensors can be converted \n","# to a Dataset object separately and combined after. \n","features_dataset = dataset.from_tensor_slices(features) \n","labels_dataset = dataset.from_tensor_slices(labels) \n","dataset = dataset.zip((features_dataset, labels_dataset)) \n","# A batched feature and label set can be converted to a Dataset \n","# in similar fashion. \n","batched_features = tf.constant([[[1, 3], [2, 3]], \n","                                [[2, 1], [1, 2]], \n","                                [[3, 3], [3, 2]]], shape=(3, 2, 2)) \n","batched_labels = tf.constant([['A', 'A'], \n","                              ['B', 'B'], \n","                              ['A', 'B']], shape=(3, 2, 1)) \n","dataset = dataset.from_tensor_slices((batched_features, batched_labels)) \n","for element in dataset.as_numpy_iterator(): \n","  print(element) "],"execution_count":35,"outputs":[{"output_type":"stream","text":["(array([[1, 3],\n","       [2, 3]], dtype=int32), array([[b'A'],\n","       [b'A']], dtype=object))\n","(array([[2, 1],\n","       [1, 2]], dtype=int32), array([[b'B'],\n","       [b'B']], dtype=object))\n","(array([[3, 3],\n","       [3, 2]], dtype=int32), array([[b'A'],\n","       [b'B']], dtype=object))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7oxILufvzyJj","colab_type":"code","outputId":"c3d4d0cc-1fd5-44e3-92b8-1ca13e0e61fc","executionInfo":{"status":"ok","timestamp":1585689374939,"user_tz":-180,"elapsed":2024,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","dataset = dataset.enumerate(start=5) #Enumerates the elements of this dataset.\n","for element in dataset.as_numpy_iterator(): \n","  print(element)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["(5, 1)\n","(6, 2)\n","(7, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_0e4NzCSzyJo","colab_type":"code","outputId":"36c6d0b6-68ae-4112-fc00-b3eebaff945f","executionInfo":{"status":"ok","timestamp":1585689377683,"user_tz":-180,"elapsed":1351,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# The nested structure of the input dataset determines the structure of \n","# elements in the resulting dataset. \n","dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)]) \n","dataset = dataset.enumerate() \n","for element in dataset.as_numpy_iterator(): \n","  print(element) "],"execution_count":37,"outputs":[{"output_type":"stream","text":["(0, array([7, 8], dtype=int32))\n","(1, array([ 9, 10], dtype=int32))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JKFU1g0izyJw","colab_type":"code","outputId":"ae242084-2c18-4b7a-ee90-d61b099aa0ec","executionInfo":{"status":"ok","timestamp":1585689381594,"user_tz":-180,"elapsed":1751,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n","dataset = dataset.filter(lambda x: x < 3) \n","list(dataset.as_numpy_iterator()) "],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2]"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"xl2FTn8rzyJ_","colab_type":"code","outputId":"46ea287f-324b-48d1-b1fc-983d02b05e29","executionInfo":{"status":"ok","timestamp":1585689385469,"user_tz":-180,"elapsed":1828,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# `tf.math.equal(x, y)` is required for equality comparison \n","def filter_fn(x): \n","  return tf.math.equal(x, 1) \n","dataset = dataset.filter(filter_fn) \n","list(dataset.as_numpy_iterator()) "],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1]"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"i0y-_EExzyKC","colab_type":"code","outputId":"5582fe19-d677-4ead-fc2f-1ca9b662ecbd","executionInfo":{"status":"ok","timestamp":1585689385472,"user_tz":-180,"elapsed":1008,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = dataset.from_tensor_slices([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \n","dataset = dataset.flat_map(lambda x: dataset.from_tensor_slices(x)) # Use flat_map if you want to make sure that the order of your dataset stays the same. \n","#For example, to flatten a dataset of batches into a dataset of their elements\n","list(dataset.as_numpy_iterator())"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3, 4, 5, 6, 7, 8, 9]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"bijMSAjxzyKH","colab_type":"code","outputId":"2197a289-0d6e-4b89-8867-08a3c2cc3481","executionInfo":{"status":"ok","timestamp":1585689389376,"user_tz":-180,"elapsed":1559,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def gen(): \n","  for i in itertools.count(1): \n","    yield (i, [1] * i) \n","dataset = tf.data.Dataset.from_generator(gen,  #Creates a Dataset whose elements are generated by generator.\n","     (tf.int64, tf.int64), \n","     (tf.TensorShape([]), tf.TensorShape([None]))) \n","list(dataset.take(3).as_numpy_iterator())"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"alq0SFvIzyKN","colab_type":"code","outputId":"838c2089-8c49-4e0d-b616-4c17e1a7014b","executionInfo":{"status":"ok","timestamp":1585689391713,"user_tz":-180,"elapsed":2402,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.from_tensors([1, 2, 3]) # Creates a Dataset with a single element, comprising the given tensors.\n","list(dataset.as_numpy_iterator()) "],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([1, 2, 3], dtype=int32)]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"-QGg5cIfzyKT","colab_type":"code","outputId":"bdb0330b-198e-4038-d840-8ea1cf96253d","executionInfo":{"status":"ok","timestamp":1585689393229,"user_tz":-180,"elapsed":802,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A')) \n","list(dataset.as_numpy_iterator()) "],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(array([1, 2, 3], dtype=int32), b'A')]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"Uy3Og8tFzyKf","colab_type":"code","colab":{}},"source":["# Preprocess 4 files concurrently, and interleave blocks of 16 records \n","# from each file. \n","filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\", \n","             \"/var/data/file3.txt\", \"/var/data/file4.txt\"] \n","dataset = tf.data.Dataset.from_tensor_slices(filenames) \n","def parse_fn(filename): \n","  return tf.data.Dataset.range(10) \n","dataset = dataset.interleave(lambda x: \n","    tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1), \n","    cycle_length=4, block_length=16) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv5DZ7qszyKk","colab_type":"code","outputId":"4a8ed0c8-3d5e-469e-e237-b36f85c79c47","executionInfo":{"status":"ok","timestamp":1585689397629,"user_tz":-180,"elapsed":884,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n","# NOTE: New lines indicate \"block\" boundaries. \n","dataset = dataset.interleave( \n","    lambda x: dataset.from_tensors(x).repeat(6), \n","    cycle_length=2, block_length=4) \n","list(dataset.as_numpy_iterator()) \n","#The cycle_length and block_length arguments control the order in which elements are produced. \n","#cycle_length controls the number of input elements that are processed concurrently.\n","#cycle_length input elements, open iterators on the returned Dataset objects, \n","# and cycle through them producing block_length consecutive elements from each iterator, "],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 2,\n"," 2,\n"," 2,\n"," 2,\n"," 1,\n"," 1,\n"," 2,\n"," 2,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 4,\n"," 4,\n"," 4,\n"," 4,\n"," 3,\n"," 3,\n"," 4,\n"," 4,\n"," 5,\n"," 5,\n"," 5,\n"," 5,\n"," 5,\n"," 5]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"_bvgKAHdzyKq","colab_type":"code","outputId":"354cd3a1-18aa-41ad-dbe9-97041f8fa73e","executionInfo":{"status":"ok","timestamp":1585689402688,"user_tz":-180,"elapsed":832,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["elements = [[1, 2], \n","            [3, 4, 5], \n","            [6, 7], \n","            [8]] \n","A = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32) \n","# Pad to the smallest per-batch size that fits all elements. \n","B = A.padded_batch(2, padded_shapes=[None]) \n","for element in B.as_numpy_iterator(): \n","  print(element) \n","#Combines consecutive elements of this dataset into padded batches.\n","#This transformation combines multiple consecutive elements of the input dataset into a single element."],"execution_count":46,"outputs":[{"output_type":"stream","text":["[[1 2 0]\n"," [3 4 5]]\n","[[6 7]\n"," [8 0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZMQojFYZzyKz","colab_type":"code","outputId":"4aee00c6-a66e-4b95-bf40-5df0fd25d9da","executionInfo":{"status":"ok","timestamp":1585689407271,"user_tz":-180,"elapsed":1444,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["dataset = tf.data.Dataset.range(3) \n","dataset = dataset.prefetch(2) \n","list(dataset.as_numpy_iterator()) "],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2]"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"MgwxDxGwzyK-","colab_type":"code","outputId":"6392642b-cc43-444e-f0ef-b6b11fe96d90","executionInfo":{"status":"ok","timestamp":1585689408141,"user_tz":-180,"elapsed":1558,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","a = tf.add(3, 5)\n","print(a)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["tf.Tensor(8, shape=(), dtype=int32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9gsFWi9kzyLF","colab_type":"code","outputId":"0d31320d-9c6d-415a-9d55-ea54a568ee04","executionInfo":{"status":"ok","timestamp":1585689408917,"user_tz":-180,"elapsed":1430,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["a = tf.constant([[3, 5], [4, 8]])\n","b = tf.constant([[1, 6], [2, 9]])\n","tf.math.add_n([a, b, a])  # [[7, 16], [10, 25]]"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n","array([[ 7, 16],\n","       [10, 25]], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"pcGaF2EPzyLJ","colab_type":"code","outputId":"e6057b1d-5fec-42d2-ae2c-4018404203e8","executionInfo":{"status":"ok","timestamp":1585689414438,"user_tz":-180,"elapsed":1200,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Launch the graph in a session.\n","with tf.compat.v1.Session() as ses:\n","     # Build a graph.\n","     a = tf.constant(5.0)\n","     b = tf.constant(6.0)\n","     c = tf.add(a, b)\n","     # Evaluate the tensor `c`.\n","     print(ses.run(c))\n","# Using the `close()` method.\n","ses.close()"],"execution_count":50,"outputs":[{"output_type":"stream","text":["11.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XmRvvl9fzyLT","colab_type":"code","outputId":"e74c48bd-57ed-425d-8760-ad24a8ab2aaa","executionInfo":{"status":"error","timestamp":1585689472981,"user_tz":-180,"elapsed":1102,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["x = 2\n","y = 3\n","op1 = tf.add(x, y)\n","op2 = tf.multiply(x, y)\n","op3 = tf.pow(op2, op1)\n","with tf.compat.v1.Session() as sess:\n","    op3 = sess.run(op3)\n","print(op3)"],"execution_count":54,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-17e52c60323e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1166\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    303\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3512\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3514\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3588\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m     raise AttributeError(\n\u001b[0;32m-> 1118\u001b[0;31m         \"Tensor.graph is meaningless when eager execution is enabled.\")\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: Tensor.graph is meaningless when eager execution is enabled."]}]},{"cell_type":"code","metadata":{"id":"tm6tsdbhzyLb","colab_type":"code","outputId":"3547e42f-df89-405f-aed9-000d16ae86a5","executionInfo":{"status":"ok","timestamp":1585689450002,"user_tz":-180,"elapsed":2199,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Launch the graph in a session.\n","with tf.compat.v1.Session() as ses:\n","     # Build a graph.\n","      x = 2\n","      y = 3\n","      add_op = tf.add(x, y)\n","      mul_op = tf.multiply(x, y)\n","      useless = tf.multiply(x, add_op)\n","      pow_op = tf.pow(add_op, mul_op)\n","      # Evaluate the tensor `c`.\n","      print(ses.run(pow_op))\n","# Using the `close()` method.\n","ses.close()"],"execution_count":52,"outputs":[{"output_type":"stream","text":["15625\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y0XxLTMPzyLi","colab_type":"code","outputId":"8c0cbc0b-d892-4c46-a15d-f4be6853e5b8","executionInfo":{"status":"ok","timestamp":1585689452806,"user_tz":-180,"elapsed":1185,"user":{"displayName":"Ali Doughman","photoUrl":"","userId":"00379597755722494243"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Creates a graph.\n","physical_devices = tf.config.list_physical_devices('GPU') \n","try: \n","  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n","except: \n","  # Invalid device or cannot modify virtual devices once initialized. \n","  pass \n","  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n","  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n","  c = tf.multiply(a, b)\n","# Creates a session with log_device_placement set to True.\n","#sess = tf.compat.v1.Session(config=tf.config.experimental(log_device_placement=True))\n","# Runs the op.\n","print(c)\n"],"execution_count":53,"outputs":[{"output_type":"stream","text":["tf.Tensor([ 1.  4.  9. 16. 25. 36.], shape=(6,), dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KTWoWwNhzyLn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}